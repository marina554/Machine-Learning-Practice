# -*- coding: utf-8 -*-
"""Flower CNN.py

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1Tm4Xjd9Ynuvf3MpCjw4uGLRwewE3lyUe
"""

import os
from tensorflow.keras.preprocessing.image import ImageDataGenerator
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout
from tensorflow.keras.callbacks import EarlyStopping
import matplotlib.pyplot as plt

# --- Data folder ---
# Folder structure: FlowerImages/class_name/images
base_dir = "FlowerImages"


# --- Data preprocessing (augmentation + normalization) ---
train_datagen = ImageDataGenerator(
    rescale=1./255,
    rotation_range=20,        # Random rotation
    width_shift_range=0.1,    # Horizontal shift
    height_shift_range=0.1,   # Vertical shift
    shear_range=0.1,          # Shear transformation
    zoom_range=0.1,           # Zoom transformation
    horizontal_flip=True,     # Horizontal flip
    validation_split=0.2      # Use 20% of the data for validation
)

# --- Validation data generator (no augmentation) ---
valid_datagen = ImageDataGenerator(
    rescale=1./255,
    validation_split=0.2
)

# Training data
train_generator = train_datagen.flow_from_directory(
    base_dir,
    target_size=(150,150),
    batch_size=16,
    class_mode='categorical',
    shuffle=True,
    subset='training'   # Use as training data
)

# Validation data
valid_generator = valid_datagen.flow_from_directory(
    base_dir,
    target_size=(150,150),
    batch_size=16,
    class_mode='categorical',
    shuffle=False,
    subset='validation'  # Use as validation data
)


# --- CNN Model ---
model = Sequential([
    Conv2D(32, (3,3), activation='relu', input_shape=(150,150,3)),
    MaxPooling2D(2,2),

    Conv2D(64, (3,3), activation='relu'),
    MaxPooling2D(2,2),

    Flatten(),
    Dense(64, activation='relu'),
    Dropout(0.5),  # Prevent overfitting
    Dense(train_generator.num_classes, activation='softmax')
])


# --- Compile the model ---
model.compile(
    optimizer='adam',
    loss='categorical_crossentropy',
    metrics=['accuracy']
)


# --- EarlyStopping callback ---
# Stop training when validation loss does not improve
early_stop = EarlyStopping(
    monitor='val_loss',       # Monitor validation loss
    patience=3,               # Stop if no improvement for 3 epochs
    restore_best_weights=True # Restore the best model weights
)


# --- Model training ---
history = model.fit(
    train_generator,
    validation_data=valid_generator,
    epochs=30,                # Set more epochs so EarlyStopping can work
    callbacks=[early_stop],   # Add EarlyStopping
    verbose=1
)

print("Training completed!")


# --- Plot accuracy ---
plt.figure(figsize=(8,4))
plt.plot(history.history['accuracy'], label='train_accuracy')
plt.plot(history.history['val_accuracy'], label='valid_accuracy')
plt.title('Training & Validation Accuracy')
plt.xlabel('Epoch')
plt.ylabel('Accuracy')
plt.legend()
plt.grid(True)
plt.show()

# --- Plot loss ---
plt.figure(figsize=(8,4))
plt.plot(history.history['loss'], label='train_loss')
plt.plot(history.history['val_loss'], label='valid_loss')
plt.title('Training & Validation Loss')
plt.xlabel('Epoch')
plt.ylabel('Loss')
plt.legend()
plt.grid(True)
plt.show()

import os
from tensorflow.keras.preprocessing.image import ImageDataGenerator
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout
from tensorflow.keras.callbacks import EarlyStopping
import matplotlib.pyplot as plt

# --- データフォルダ ---
# FlowerImages/クラス名/画像 というフォルダ構成を想定
base_dir = "FlowerImages"


# --- データ前処理（データ拡張 + 正規化） ---
train_datagen = ImageDataGenerator(
    rescale=1./255,
    rotation_range=20,        # ランダム回転
    width_shift_range=0.1,    # 横方向の平行移動
    height_shift_range=0.1,   # 縦方向の平行移動
    shear_range=0.1,          # シアー変換
    zoom_range=0.1,           # ズーム
    horizontal_flip=True,     # 水平方向反転
    validation_split=0.2      # データの20%を検証用に割り当て
)

# --- 検証用データ生成（データ拡張なし） ---
valid_datagen = ImageDataGenerator(
    rescale=1./255,
    validation_split=0.2
)

# 訓練データ生成
train_generator = train_datagen.flow_from_directory(
    base_dir,
    target_size=(150,150),
    batch_size=16,
    class_mode='categorical',
    shuffle=True,
    subset='training'   # 訓練用
)

# 検証データ生成
valid_generator = valid_datagen.flow_from_directory(
    base_dir,
    target_size=(150,150),
    batch_size=16,
    class_mode='categorical',
    shuffle=False,
    subset='validation'  # 検証用
)


# --- CNNモデル ---
model = Sequential([
    Conv2D(32, (3,3), activation='relu', input_shape=(150,150,3)),
    MaxPooling2D(2,2),

    Conv2D(64, (3,3), activation='relu'),
    MaxPooling2D(2,2),

    Flatten(),
    Dense(64, activation='relu'),
    Dropout(0.5),  # 過学習防止
    Dense(train_generator.num_classes, activation='softmax')
])


# --- モデルのコンパイル ---
model.compile(
    optimizer='adam',
    loss='categorical_crossentropy',
    metrics=['accuracy']
)


# --- EarlyStopping の設定 ---
# val_loss（検証損失）が改善しなくなったら学習を止める
early_stop = EarlyStopping(
    monitor='val_loss',       # 改善を監視する値
    patience=3,               # 3エポック改善しなければ停止
    restore_best_weights=True # 一番性能が良かった重みを復元
)


# --- モデルの学習 ---
history = model.fit(
    train_generator,
    validation_data=valid_generator,
    epochs=30,                # EarlyStoppingするため少し長めに
    callbacks=[early_stop],   # ここに EarlyStopping を追加
    verbose=1
)

print("Training completed!")


# --- 精度のプロット ---
plt.figure(figsize=(8,4))
plt.plot(history.history['accuracy'], label='train_accuracy')
plt.plot(history.history['val_accuracy'], label='valid_accuracy')
plt.title('Training & Validation Accuracy')
plt.xlabel('Epoch')
plt.ylabel('Accuracy')
plt.legend()
plt.grid(True)
plt.show()

# --- 損失のプロット ---
plt.figure(figsize=(8,4))
plt.plot(history.history['loss'], label='train_loss')
plt.plot(history.history['val_loss'], label='valid_loss')
plt.title('Training & Validation Loss')
plt.xlabel('Epoch')
plt.ylabel('Loss')
plt.legend()
plt.grid(True)
plt.show()